# Data Engineering for Machine Learning using Apache Spark <br/>

## Description <br/>
This module begins with Apache Spark Structured Streaming and its role in processing streaming data with Spark SQL. You will acquire knowledge about key terms associated with Structured Streaming. The module then covers the Extract-Transform-Load process and provides hands-on experience in transferring data from one source to another destination with varying data formats or structures. Additionally, you will gain a practical understanding of feature extraction and transformation using Spark extract and transform features. The module also delves into machine learning pipelines using Spark, demonstrating the process and benefits involved. Lastly, you will grasp the concept of model persistence and its significant role in Machine Learning. <br/>

## Objectives <br/>
* Define Spark SQL and Identify the steps to use Spark SQL for DataFrame operations.
* Explain the concept of Structured Streaming, including operations on streaming data, streaming listeners, and checkpointing.
* Identify the different data sources available for Structured Streaming, supported streaming output modes, and the various data sinks that can be used.
* Define the ETL (Extract, Transform, Load) process and its significance in data processing.
* Describe how to perform data extraction, transformation, and loading using Apache Spark.
* Highlight the importance of feature extraction and feature transformation in data analysis.
* Explain the process of feature transformation and outline the necessary steps to perform it using Spark.
* Provide an overview of machine learning pipelines and outline the steps involved in creating them.
* Discuss the advantages of using machine learning pipelines for data analysis and model training.
* Explain how Spark can be used to implement machine learning pipelines, emphasizing their benefits.
* Define model persistence and elaborate on its advantages in the context of machine learning.