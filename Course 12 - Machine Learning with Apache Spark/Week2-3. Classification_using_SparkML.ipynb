{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using SparkML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color: red'>The purpose of this lab is to show you how to use SparkML to classify varieties of beans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <a href=\"#Objectives\">Objectives\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Datasets\">Datasets\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Setup\">Setup\n",
    "    </a>\n",
    "    <ol>\n",
    "      <li>\n",
    "        <a href=\"#Installing-Required-Libraries\">Installing Required Libraries\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Importing-Required-Libraries\">Importing Required Libraries\n",
    "        </a>\n",
    "      </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Examples\">Examples\n",
    "    </a>\n",
    "    <ol>\n",
    "    <li>\n",
    "      <a href=\"#Task-1---Create-a-spark-session\">Task 1 - Create a spark session\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-2---Load-the-data-in-a-csv-file-into-a-dataframe\">Task 2 - Load the data in a csv file into a dataframe\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-3---Identify-the-label-column-and-the-input-columns\">Task 3 - Identify the label column and the input columns\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-4---Split-the-data\">Task 4 - Split the data\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-5---Build-and-Train-a-Logistic-Regression-Model\">Task 5 - Build and Train a Logistic Regression Model\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-6---Evaluate-the-model\">Task 6 - Evaluate the model\n",
    "      </a>\n",
    "    </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Exercises\">Exercises\n",
    "    </a>\n",
    "  </li>\n",
    "  <ol>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-1---Create-a-spark-session\">Exercise 1 - Create a spark session\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-2---Load-the-data-in-a-csv-file-into-a-dataframe\">Exercise 2 - Load the data in a csv file into a dataframe\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-3---Identify-the-label-column-and-the-input-columns\">Exercise 3 - Identify the label column and the input columns\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-4---Split-the-data\">Exercise 4 - Split the data\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-5---Build-and-Train-a-Logistic-Regression-Model\">Exercise 5 - Build and Train a Logistic Regression Model\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-6---Evaluate-the-model\">Exercise 6 - Evaluate the model\n",
    "      </a>\n",
    "    </li>\n",
    "  </ol>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Use PySpark to connect to a spark cluster.\n",
    " - Create a spark session.\n",
    " - Read a csv file into a data frame.\n",
    " - Split the dataset into training and testing sets.\n",
    " - Use VectorAssembler to combine multiple columns into a single vector column\n",
    " - Use Logistic Regression to build a classification model.\n",
    " - Use metrics to evaluate the model.\n",
    " - Stop the spark session\n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this lab you will be using dataset(s):\n",
    "\n",
    " - Dry Bean dataset. Available at https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset \n",
    " - Modified version of iris dataset. Available at https://archive.ics.uci.edu/ml/datasets/Iris \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to connect to this cluster.\n",
    "\n",
    "If you wish to download this jupyter notebook and run on your local computer, follow the instructions mentioned <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/labs/Connecting_to_spark_cluster_using_Skills_Network_labs.ipynb\">here.</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#import functions/Classes for sparkml\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# import functions/Classes for metrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/26 13:41:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Create SparkSession\n",
    "#Ignore any warnings by SparkSession command\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Classification using SparkML\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Load the data in a csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 13:41:43--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/drybeans.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2484759 (2.4M) [text/csv]\n",
      "Saving to: ‘drybeans.csv’\n",
      "\n",
      "drybeans.csv        100%[===================>]   2.37M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2024-01-26 13:41:43 (45.3 MB/s) - ‘drybeans.csv’ saved [2484759/2484759]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/drybeans.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into the spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|Class|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|SEKER|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|SEKER|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|SEKER|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|SEKER|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|SEKER|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the spark.read.csv function we load the data into a dataframe.\n",
    "# the header = True mentions that there is a header row in out csv file\n",
    "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
    "\n",
    "# Load mpg dataset\n",
    "beans_data = spark.read.csv(\"drybeans.csv\", header=True, inferSchema=True)\n",
    "beans_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the schema of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Perimeter: double (nullable = true)\n",
      " |-- MajorAxisLength: double (nullable = true)\n",
      " |-- MinorAxisLength: double (nullable = true)\n",
      " |-- AspectRation: double (nullable = true)\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- ConvexArea: integer (nullable = true)\n",
      " |-- EquivDiameter: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beans_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top 5 rows of selected columns from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+-----------+-----------+-----+\n",
      "| Area|Perimeter|   Solidity|  roundness|Compactness|Class|\n",
      "+-----+---------+-----------+-----------+-----------+-----+\n",
      "|28395|  610.291|0.988855999|0.958027126|0.913357755|SEKER|\n",
      "|28734|  638.018|0.984985603|0.887033637|0.953860842|SEKER|\n",
      "|29380|   624.11|0.989558774|0.947849473|0.908774239|SEKER|\n",
      "|30008|  645.884|0.976695743|0.903936374|0.928328835|SEKER|\n",
      "|30140|  620.134| 0.99089325|0.984877069|0.970515523|SEKER|\n",
      "+-----+---------+-----------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beans_data.select([\"Area\",\"Perimeter\",\"Solidity\",\"roundness\",\"Compactness\",\"Class\"]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the value counts for the column 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   Class|count|\n",
      "+--------+-----+\n",
      "|  BOMBAY|  522|\n",
      "|BARBUNYA| 1322|\n",
      "|    CALI| 1630|\n",
      "|   HOROZ| 1928|\n",
      "|   SEKER| 2027|\n",
      "|    SIRA| 2636|\n",
      "|DERMASON| 3546|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beans_data.groupBy(\"Class\").count().orderBy(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the string column \"Class\" into a numberic column named \"Label\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|Class|label|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|SEKER|  2.0|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|SEKER|  2.0|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|SEKER|  2.0|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|SEKER|  2.0|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|SEKER|  2.0|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Class column from string to numerical values\n",
    "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"label\")\n",
    "beans_data = indexer.fit(beans_data).transform(beans_data)\n",
    "beans_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the value counts for the column 'label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  6.0|  522|\n",
      "|  5.0| 1322|\n",
      "|  4.0| 1630|\n",
      "|  3.0| 1928|\n",
      "|  2.0| 2027|\n",
      "|  1.0| 2636|\n",
      "|  0.0| 3546|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beans_data.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Identify the label column and the input columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask the VectorAssembler to group a bunch of inputCols as single column named \"features\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"Area\",\"Perimeter\",\"Solidity\",\"roundness\",\"Compactness\" as input columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+--------------------+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|Class|label|            features|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+--------------------+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|SEKER|  2.0|[28395.0,610.291,...|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|SEKER|  2.0|[28734.0,638.018,...|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|SEKER|  2.0|[29380.0,624.11,0...|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|SEKER|  2.0|[30008.0,645.884,...|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|SEKER|  2.0|[30140.0,620.134,...|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"Area\", \"Perimeter\", \"Solidity\", \"roundness\", \"Compactness\"], outputCol=\"features\")\n",
    "beans_transformed_data = assembler.transform(beans_data)\n",
    "beans_transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the assembled \"features\" and the label column \"Class\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|            features|label|Class|\n",
      "+--------------------+-----+-----+\n",
      "|[28395.0,610.291,...|  2.0|SEKER|\n",
      "|[28734.0,638.018,...|  2.0|SEKER|\n",
      "|[29380.0,624.11,0...|  2.0|SEKER|\n",
      "|[30008.0,645.884,...|  2.0|SEKER|\n",
      "|[30140.0,620.134,...|  2.0|SEKER|\n",
      "|[30279.0,634.927,...|  2.0|SEKER|\n",
      "|[30477.0,670.033,...|  2.0|SEKER|\n",
      "|[30519.0,629.727,...|  2.0|SEKER|\n",
      "|[30685.0,635.681,...|  2.0|SEKER|\n",
      "|[30834.0,631.934,...|  2.0|SEKER|\n",
      "|[30917.0,640.765,...|  2.0|SEKER|\n",
      "|[31091.0,638.558,...|  2.0|SEKER|\n",
      "|[31107.0,640.594,...|  2.0|SEKER|\n",
      "|[31158.0,642.626,...|  2.0|SEKER|\n",
      "|[31158.0,641.105,...|  2.0|SEKER|\n",
      "|[31178.0,636.888,...|  2.0|SEKER|\n",
      "|[31202.0,644.454,...|  2.0|SEKER|\n",
      "|[31203.0,639.782,...|  2.0|SEKER|\n",
      "|[31272.0,638.666,...|  2.0|SEKER|\n",
      "|[31335.0,635.011,...|  2.0|SEKER|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beans_transformed_data.select([\"features\", \"label\", \"Class\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Split the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data set in the ratio of 70:30. 70% training data, 30% testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "(training_data, testing_data) = beans_transformed_data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random_state variable \"seed\" controls the shuffling applied to the data before applying the split. Pass the same integer for reproducible output across multiple function calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Build and Train a Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LR model and train the model using the training data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/26 14:13:50 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/01/26 14:13:50 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "# Ignore any warnings\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 - Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model is now trained. We use the testing data to make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|   Class|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|20464|  528.408|     191.249312|    136.3684624| 1.402445321| 0.701123073|     20772|  161.4173908|0.747406866|0.985172347|0.921004226|0.844015537| 0.009345647| 0.002925438| 0.712362227| 0.999049071|DERMASON|  0.0|[20464.0,528.408,...|[21.3852294258049...|[0.99996889450809...|       0.0|\n",
      "|20548|  524.736|    183.9652515|    142.6723878| 1.289424354| 0.631298586|     20825|  161.7483421|0.759686483|0.986698679|0.937772948| 0.87923312| 0.008952952| 0.003300366|  0.77305088| 0.996790631|DERMASON|  0.0|[20548.0,524.736,...|[22.1252627088355...|[0.99962875207878...|       0.0|\n",
      "|20711|  525.413|    186.0791494|    142.0816797| 1.309663214| 0.645742704|     20988|  162.3886209|0.793524904|0.986801982|0.942777707|0.872685744| 0.008984556| 0.003214459| 0.761580408| 0.997413845|DERMASON|  0.0|[20711.0,525.413,...|[22.1258949705074...|[0.99977133721822...|       0.0|\n",
      "|21570|  538.454|    196.5372798|    139.8773025|  1.40506913| 0.702474661|     21820|   165.721987| 0.81245998|0.988542621|0.934894907|0.843208918| 0.009111603| 0.002841288| 0.711001279| 0.999005949|DERMASON|  0.0|[21570.0,538.454,...|[21.0613492590234...|[0.99994778630656...|       0.0|\n",
      "|21666|  531.318|    187.1686348|    147.6309493| 1.267814342| 0.614702534|     21877|  166.0903609|0.810913991|0.990355168|0.964449616|0.887383514| 0.008638818|   0.0033043| 0.787449501| 0.998339771|DERMASON|  0.0|[21666.0,531.318,...|[22.2769239181805...|[0.99853123649347...|       0.0|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+--------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing data\n",
    "predictions = model.transform(testing_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8937376725838264\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.8934405575280979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision =\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.8937376725838265\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall =\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score =  0.8933106212109942\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(\"F1 score = \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will use sparkml to classify the iris flower dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spark session with appname \"Iris Flower Classification\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Iris Flower Classification\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Load the data in a csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 14:21:13--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/iris.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4612 (4.5K) [text/csv]\n",
      "Saving to: ‘iris.csv’\n",
      "\n",
      "iris.csv            100%[===================>]   4.50K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-01-26 14:21:13 (39.9 MB/s) - ‘iris.csv’ saved [4612/4612]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a spark dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display top 5 rows from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_data = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
    "iris_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Identify the label column and the input columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the string column \"Species\" to a column of numerical values named \"label\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+-----+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|label|\n",
      "+-------------+------------+-------------+------------+-----------+-----+\n",
      "|          5.1|         3.5|          1.4|         0.2|Iris-setosa|  0.0|\n",
      "|          4.9|         3.0|          1.4|         0.2|Iris-setosa|  0.0|\n",
      "|          4.7|         3.2|          1.3|         0.2|Iris-setosa|  0.0|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|  0.0|\n",
      "|          5.0|         3.6|          1.4|         0.2|Iris-setosa|  0.0|\n",
      "+-------------+------------+-------------+------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
    "iris_data = indexer.fit(iris_data).transform(iris_data)\n",
    "iris_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==================================================>    (183 + 9) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   50|\n",
      "|  2.0|   50|\n",
      "|  1.0|   50|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "iris_data.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble the columns columns \"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\" into a single column named \"features\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+-----+-----------------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|label|         features|\n",
      "+-------------+------------+-------------+------------+-----------+-----+-----------------+\n",
      "|          5.1|         3.5|          1.4|         0.2|Iris-setosa|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|          4.9|         3.0|          1.4|         0.2|Iris-setosa|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|          4.7|         3.2|          1.3|         0.2|Iris-setosa|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|          5.0|         3.6|          1.4|         0.2|Iris-setosa|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-------------+------------+-------------+------------+-----------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"], outputCol=\"features\")\n",
    "iris_transformed_data = assembler.transform(iris_data)\n",
    "iris_transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the vectorized features and label columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "|[5.4,3.9,1.7,0.4]|  0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|\n",
      "|[5.0,3.4,1.5,0.2]|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "|[5.4,3.7,1.5,0.2]|  0.0|\n",
      "|[4.8,3.4,1.6,0.2]|  0.0|\n",
      "|[4.8,3.0,1.4,0.1]|  0.0|\n",
      "|[4.3,3.0,1.1,0.1]|  0.0|\n",
      "|[5.8,4.0,1.2,0.2]|  0.0|\n",
      "|[5.7,4.4,1.5,0.4]|  0.0|\n",
      "|[5.4,3.9,1.3,0.4]|  0.0|\n",
      "|[5.1,3.5,1.4,0.3]|  0.0|\n",
      "|[5.7,3.8,1.7,0.3]|  0.0|\n",
      "|[5.1,3.8,1.5,0.3]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_transformed_data.select(\"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Split the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing sets in the ratio of 75:25. Use 42 as seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "(training_data, testing_data) = iris_transformed_data.randomSplit([0.75, 0.25], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Build and Train a Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Logistic Regression model and train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the values using the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6 - Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model is now trained. Make the model predict on testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+---------------+-----+-----------------+--------------------+--------------------+----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        Species|label|         features|       rawPrediction|         probability|prediction|\n",
      "+-------------+------------+-------------+------------+---------------+-----+-----------------+--------------------+--------------------+----------+\n",
      "|          4.4|         2.9|          1.4|         0.2|    Iris-setosa|  0.0|[4.4,2.9,1.4,0.2]|[58.3186805491634...|[1.0,1.7678100427...|       0.0|\n",
      "|          4.4|         3.0|          1.3|         0.2|    Iris-setosa|  0.0|[4.4,3.0,1.3,0.2]|[63.8500908164191...|[1.0,7.4692072911...|       0.0|\n",
      "|          4.4|         3.2|          1.3|         0.2|    Iris-setosa|  0.0|[4.4,3.2,1.3,0.2]|[72.0448085634866...|[1.0,4.0970790073...|       0.0|\n",
      "|          4.8|         3.1|          1.6|         0.2|    Iris-setosa|  0.0|[4.8,3.1,1.6,0.2]|[60.2424930954757...|[1.0,9.9098950813...|       0.0|\n",
      "|          4.9|         2.4|          3.3|         1.0|Iris-versicolor|  1.0|[4.9,2.4,3.3,1.0]|[-19.129303155614...|[2.64829034490762...|       1.0|\n",
      "+-------------+------------+-------------+------------+---------------+-----+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing data\n",
    "predictions = model.transform(testing_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the metrics :\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9698275862068966\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision =\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall =\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.9659170414792604\n"
     ]
    }
   ],
   "source": [
    "# F1 \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "print(\"F1 score =\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations you have completed this lab.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMBD0231ENSkillsNetwork866-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-04-27|0.1|Ramesh Sannareddy|Initial Version Created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
