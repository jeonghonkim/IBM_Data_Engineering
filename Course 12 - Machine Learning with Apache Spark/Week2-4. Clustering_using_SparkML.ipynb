{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering using SparkML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color: red'>The purpose of this lab is to show you how to use SparkML to cluster data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "<ol>\n",
    "  <li>\n",
    "    <a href=\"#Objectives\">Objectives\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Datasets\">Datasets\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Setup\">Setup\n",
    "    </a>\n",
    "    <ol>\n",
    "      <li>\n",
    "        <a href=\"#Installing-Required-Libraries\">Installing Required Libraries\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Importing-Required-Libraries\">Importing Required Libraries\n",
    "        </a>\n",
    "      </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Examples\">Examples\n",
    "    </a>\n",
    "    <ol>\n",
    "      <li>\n",
    "        <a href=\"#Task-1---Create-a-spark-session\">Task 1 - Create a spark session\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Task-2---Load-the-data-in-a-csv-file-into-a-dataframe\">Task 2 - Load the data in a csv file into a dataframe\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Task-3---Create-a-feature-vector\">Task 3 - Create a feature vector\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Task-4---Create-a-clustering-model\">Task 4 - Create a clustering model\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Task-5---Print-Cluster-Centers\">Task 5 - Print Cluster Centers\n",
    "        </a>\n",
    "      </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Exercises\">Exercises\n",
    "    </a>\n",
    "  </li>\n",
    "  <ol>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-1---Create-a-spark-session\">Exercise 1 - Create a spark session\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-2---Load-the-data-in-a-csv-file-into-a-dataframe\">Exercise 2 - Load the data in a csv file into a dataframe\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-3---Create-a-feature-vector\">Exercise 3 - Create a feature vector\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-4---Create-a-clustering-model\">Exercise 4 - Create a clustering model\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-5---Print-Cluster-Centers\">Exercise 5 - Print Cluster Centers\n",
    "      </a>\n",
    "    </li>\n",
    "  </ol>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Use PySpark to connect to a spark cluster.\n",
    " - Create a spark session.\n",
    " - Read a csv file into a data frame.\n",
    " - Use KMeans algorithm to cluster the data\n",
    " - Stop the spark session\n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this lab you will be using dataset(s):\n",
    "\n",
    " - Modified version of Wholesale customers dataset. Original dataset available at https://archive.ics.uci.edu/ml/datasets/Wholesale+customers \n",
    " - Seeds dataset. Available at https://archive.ics.uci.edu/ml/datasets/seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to connect to this cluster.\n",
    "\n",
    "If you wish to download this jupyter notebook and run on your local computer, follow the instructions mentioned <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/labs/Connecting_to_spark_cluster_using_Skills_Network_labs.ipynb\">here.</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#import functions/Classes for sparkml\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/26 14:43:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/26 14:43:59 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#Create SparkSession\n",
    "#Ignore any warnings by SparkSession command\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Clustering using SparkML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Load the data in a csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 14:44:04--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/customers.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8909 (8.7K) [text/csv]\n",
      "Saving to: ‘customers.csv’\n",
      "\n",
      "customers.csv       100%[===================>]   8.70K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-01-26 14:44:04 (18.7 MB/s) - ‘customers.csv’ saved [8909/8909]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/customers.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into the spark dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top 5 rows from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----------+\n",
      "|Fresh_Food|Milk|Grocery|Frozen_Food|\n",
      "+----------+----+-------+-----------+\n",
      "|     12669|9656|   7561|        214|\n",
      "|      7057|9810|   9568|       1762|\n",
      "|      6353|8808|   7684|       2405|\n",
      "|     13265|1196|   4221|       6404|\n",
      "|     22615|5410|   7198|       3915|\n",
      "+----------+----+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the spark.read.csv function we load the data into a dataframe.\n",
    "# the header = True mentions that there is a header row in out csv file\n",
    "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
    "\n",
    "# Load customers dataset\n",
    "customer_data = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
    "customer_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the schema of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Fresh_Food: integer (nullable = true)\n",
      " |-- Milk: integer (nullable = true)\n",
      " |-- Grocery: integer (nullable = true)\n",
      " |-- Frozen_Food: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Each row in this dataset is about a customer. The columns indicate the orders placed\n",
    "# by a customer for Fresh_food, Milk, Grocery and Frozen_Food\n",
    "customer_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Create a feature vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----------+--------------------+\n",
      "|Fresh_Food|Milk|Grocery|Frozen_Food|            features|\n",
      "+----------+----+-------+-----------+--------------------+\n",
      "|     12669|9656|   7561|        214|[12669.0,9656.0,7...|\n",
      "|      7057|9810|   9568|       1762|[7057.0,9810.0,95...|\n",
      "|      6353|8808|   7684|       2405|[6353.0,8808.0,76...|\n",
      "|     13265|1196|   4221|       6404|[13265.0,1196.0,4...|\n",
      "|     22615|5410|   7198|       3915|[22615.0,5410.0,7...|\n",
      "+----------+----+-------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble the features into a single vector column\n",
    "feature_cols = [\"Fresh_Food\", \"Milk\", \"Grocery\", \"Frozen_Food\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "customer_transformed_data = assembler.transform(customer_data)\n",
    "customer_transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Create a clustering model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must tell the KMeans algorithm how many clusters to create out of your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_clusters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a KMeans clustering model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(k = number_of_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit the model on the dataset<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/26 14:48:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/01/26 14:48:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = kmeans.fit(customer_transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Print Cluster Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model is now trained. Time to evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----------+--------------------+----------+\n",
      "|Fresh_Food|Milk|Grocery|Frozen_Food|            features|prediction|\n",
      "+----------+----+-------+-----------+--------------------+----------+\n",
      "|     12669|9656|   7561|        214|[12669.0,9656.0,7...|         0|\n",
      "|      7057|9810|   9568|       1762|[7057.0,9810.0,95...|         0|\n",
      "|      6353|8808|   7684|       2405|[6353.0,8808.0,76...|         0|\n",
      "|     13265|1196|   4221|       6404|[13265.0,1196.0,4...|         0|\n",
      "|     22615|5410|   7198|       3915|[22615.0,5410.0,7...|         2|\n",
      "+----------+----+-------+-----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the dataset and display the results\n",
    "predictions = model.transform(customer_transformed_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display how many customers are there in each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:==========================================>           (158 + 9) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|  331|\n",
      "|         1|   49|\n",
      "|         2|   60|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('prediction').count().orderBy('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stop spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SparkSession with appname \"Seed Clustering\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/26 14:50:59 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Seed Clustering\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Load the data in a csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 14:51:09--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/seeds.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8973 (8.8K) [text/csv]\n",
      "Saving to: ‘seeds.csv’\n",
      "\n",
      "seeds.csv           100%[===================>]   8.76K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-01-26 14:51:09 (14.6 MB/s) - ‘seeds.csv’ saved [8973/8973]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download seed dataset\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/seeds.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the seed dataset and show top 5 rows of the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "|15.26|    14.84|      0.871|           5.763|          3.312|                2.221|                   5.22|\n",
      "|14.88|    14.57|     0.8811|           5.554|          3.333|                1.018|                  4.956|\n",
      "|14.29|    14.09|      0.905|           5.291|          3.337|                2.699|                  4.825|\n",
      "|13.84|    13.94|     0.8955|           5.324|          3.379|                2.259|                  4.805|\n",
      "|16.14|    14.99|     0.9034|           5.658|          3.562|                1.355|                  5.175|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_data = spark.read.csv(\"seeds.csv\", header=True, inferSchema=True)\n",
    "seed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the schema of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: double (nullable = true)\n",
      " |-- perimeter: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- length of kernel: double (nullable = true)\n",
      " |-- width of kernel: double (nullable = true)\n",
      " |-- asymmetry coefficient: double (nullable = true)\n",
      " |-- length of kernel groove: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Create a feature vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble all columns into a single vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|            features|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+\n",
      "|15.26|    14.84|      0.871|           5.763|          3.312|                2.221|                   5.22|[15.26,14.84,0.87...|\n",
      "|14.88|    14.57|     0.8811|           5.554|          3.333|                1.018|                  4.956|[14.88,14.57,0.88...|\n",
      "|14.29|    14.09|      0.905|           5.291|          3.337|                2.699|                  4.825|[14.29,14.09,0.90...|\n",
      "|13.84|    13.94|     0.8955|           5.324|          3.379|                2.259|                  4.805|[13.84,13.94,0.89...|\n",
      "|16.14|    14.99|     0.9034|           5.658|          3.562|                1.355|                  5.175|[16.14,14.99,0.90...|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"area\", \"perimeter\", \"compactness\", \"length of kernel\", \"width of kernel\", \"asymmetry coefficient\", \"length of kernel groove\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "seed_transformed_data = assembler.transform(seed_data)\n",
    "seed_transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Create a clustering model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 7 clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(k = 7)\n",
    "model = kmeans.fit(seed_transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Print Cluster Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(seed_transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------------------------------+----------+\n",
      "|area |perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|features                                    |prediction|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------------------------------+----------+\n",
      "|15.26|14.84    |0.871      |5.763           |3.312          |2.221                |5.22                   |[15.26,14.84,0.871,5.763,3.312,2.221,5.22]  |6         |\n",
      "|14.88|14.57    |0.8811     |5.554           |3.333          |1.018                |4.956                  |[14.88,14.57,0.8811,5.554,3.333,1.018,4.956]|6         |\n",
      "|14.29|14.09    |0.905      |5.291           |3.337          |2.699                |4.825                  |[14.29,14.09,0.905,5.291,3.337,2.699,4.825] |0         |\n",
      "|13.84|13.94    |0.8955     |5.324           |3.379          |2.259                |4.805                  |[13.84,13.94,0.8955,5.324,3.379,2.259,4.805]|0         |\n",
      "|16.14|14.99    |0.9034     |5.658           |3.562          |1.355                |5.175                  |[16.14,14.99,0.9034,5.658,3.562,1.355,5.175]|6         |\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------\n",
      " area                    | 15.26                                        \n",
      " perimeter               | 14.84                                        \n",
      " compactness             | 0.871                                        \n",
      " length of kernel        | 5.763                                        \n",
      " width of kernel         | 3.312                                        \n",
      " asymmetry coefficient   | 2.221                                        \n",
      " length of kernel groove | 5.22                                         \n",
      " features                | [15.26,14.84,0.871,5.763,3.312,2.221,5.22]   \n",
      " prediction              | 6                                            \n",
      "-RECORD 1---------------------------------------------------------------\n",
      " area                    | 14.88                                        \n",
      " perimeter               | 14.57                                        \n",
      " compactness             | 0.8811                                       \n",
      " length of kernel        | 5.554                                        \n",
      " width of kernel         | 3.333                                        \n",
      " asymmetry coefficient   | 1.018                                        \n",
      " length of kernel groove | 4.956                                        \n",
      " features                | [14.88,14.57,0.8811,5.554,3.333,1.018,4.956] \n",
      " prediction              | 6                                            \n",
      "-RECORD 2---------------------------------------------------------------\n",
      " area                    | 14.29                                        \n",
      " perimeter               | 14.09                                        \n",
      " compactness             | 0.905                                        \n",
      " length of kernel        | 5.291                                        \n",
      " width of kernel         | 3.337                                        \n",
      " asymmetry coefficient   | 2.699                                        \n",
      " length of kernel groove | 4.825                                        \n",
      " features                | [14.29,14.09,0.905,5.291,3.337,2.699,4.825]  \n",
      " prediction              | 0                                            \n",
      "-RECORD 3---------------------------------------------------------------\n",
      " area                    | 13.84                                        \n",
      " perimeter               | 13.94                                        \n",
      " compactness             | 0.8955                                       \n",
      " length of kernel        | 5.324                                        \n",
      " width of kernel         | 3.379                                        \n",
      " asymmetry coefficient   | 2.259                                        \n",
      " length of kernel groove | 4.805                                        \n",
      " features                | [13.84,13.94,0.8955,5.324,3.379,2.259,4.805] \n",
      " prediction              | 0                                            \n",
      "-RECORD 4---------------------------------------------------------------\n",
      " area                    | 16.14                                        \n",
      " perimeter               | 14.99                                        \n",
      " compactness             | 0.9034                                       \n",
      " length of kernel        | 5.658                                        \n",
      " width of kernel         | 3.562                                        \n",
      " asymmetry coefficient   | 1.355                                        \n",
      " length of kernel groove | 5.175                                        \n",
      " features                | [16.14,14.99,0.9034,5.658,3.562,1.355,5.175] \n",
      " prediction              | 6                                            \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(n=5, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:=====================================>               (143 + 10) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|   29|\n",
      "|         1|   13|\n",
      "|         2|   48|\n",
      "|         3|   29|\n",
      "|         4|   26|\n",
      "|         5|   43|\n",
      "|         6|   22|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('prediction').count().orderBy('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stop spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations you have completed this lab.<br>\n",
    "You are encouraged to create different number of clusters using the same dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMBD0231ENSkillsNetwork866-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-05-01|0.1|Ramesh Sannareddy|Initial Version Created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
